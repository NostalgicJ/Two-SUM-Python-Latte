# chatbot.py â€” .env ê°•ì œ ë¡œë“œ / SDK í˜¸í™˜ / 429Â·503 ì¬ì‹œë„ / í‚¤ ì˜¤ë¥˜ ì•ˆë‚´
# í•„ìš”: pip install python-dotenv google-genai
from __future__ import annotations

import os, sys, re, time, random
import json  # [ì¶”ê°€] JSON ë¼ì´ë¸ŒëŸ¬ë¦¬
from datetime import datetime  # [ì¶”ê°€] ì‹œê°„ ê¸°ë¡ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from pathlib import Path
from typing import List, Dict, Any
from dotenv import load_dotenv
from google import genai
from google.genai.errors import ClientError, ServerError

# â”€â”€ 0) í™˜ê²½ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ ìœ„ì¹˜ì™€ ë¬´ê´€í•˜ê²Œ chatbot.pyì™€ ê°™ì€ í´ë”ì˜ .envë¥¼ ê°•ì œ ë¡œë“œ
load_dotenv(dotenv_path=Path(__file__).with_name(".env"))

API_KEY = (os.getenv("GEMINI_API_KEY") or "").strip()
if not API_KEY:
    print("âŒ .envì— GEMINI_API_KEY ì—†ìŒ ë˜ëŠ” ë¹ˆ ê°’"); sys.exit(1)
# ì°¸ê³ : Google AI Studio í‚¤ëŠ” ë³´í†µ 'AIza'ë¡œ ì‹œì‘(ê¶Œì¥ ì²´í¬)
if not API_KEY.startswith("AIza"):
    print("âš ï¸  í‚¤ í˜•ì‹ì´ ì¼ë°˜ì ì¸ Google AI Studio í‚¤(AIza...)ì™€ ë‹¤ë¦…ë‹ˆë‹¤. í‚¤ ì¶œì²˜/ì¢…ë¥˜ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

MODEL = os.getenv("MODEL", "gemini-2.5-flash").strip()

try:
    client = genai.Client(api_key=API_KEY)
except Exception as e:
    print(f"âŒ genai.Client ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"); sys.exit(1)

# [ìˆ˜ì •ë¨] 1ë‹¨ê³„: 'ì¸ì§€/ë‡Œê³¼í•™ ê¸°ë°˜ ì‹¬ë¦¬ íŒŒì•…' í”„ë¡¬í”„íŠ¸ ì ìš©
SYSTEM = """
[ì—­í• ]
ë„ˆëŠ” ì‚¬ìš©ìì˜ ë§ˆìŒì„ ê¹Šì´ ê³µê°í•˜ë©° ê·¸ ì´ë©´ì˜ 'ì‹¬ë¦¬ì  ì¸ì§€ íŒ¨í„´'ì„ íŒŒì•…í•˜ëŠ” 'ì‹¬ë¦¬ ë¶„ì„ ë´‡'ì´ì•¼.

[ì§€ì‹ ê¸°ë°˜]
ë„ˆì˜ ë¶„ì„ì€ 'ë‡Œê³¼í•™' ë° 'ì¸ì§€í–‰ë™ì¹˜ë£Œ(CBT)'ì˜ ê¸°ë³¸ ì›ì¹™ì— ê¸°ë°˜í•´. 
í•µì‹¬ì€ [A: ê³„ê¸°/ì‚¬ê±´] -> [B: ìë™ì  ì‚¬ê³ /ì‹ ë…] -> [C: ê°ì •/í–‰ë™]ì˜ ì—°ê²°ê³ ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ê±°ì•¼.

[ëª©í‘œ]
- 1ìˆœìœ„ (ìƒë‹´): ì‚¬ìš©ìì˜ ê°ì •[C]ì„ ë¹„íŒë‹¨ì ìœ¼ë¡œ ìˆ˜ìš©í•˜ê³  ê³µê°í•˜ë©° ì•ˆì „í•œ ëŒ€í™” í™˜ê²½ì„ ì œê³µí•´.
- 2ìˆœìœ„ (íŒŒì•…): ì‚¬ìš©ìê°€ ê²ªëŠ” ê°ì •[C]ì˜ ê·¼ì›ì´ ë˜ëŠ” 'ê³„ê¸°'[A]ì™€, ê·¸ ê³„ê¸°ë¥¼ í•´ì„í•˜ëŠ” 'ìë™ì  ì‚¬ê³ '[B]ê°€ ë¬´ì—‡ì¸ì§€ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì„ í†µí•´ íŒŒì•…í•´.
- (ì°¸ê³ : ì´ 'íŒŒì•…'ì€ ë‚˜ì¤‘ì— DBì— ê¸°ë¡í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•œ ê²ƒì´ë©°, ì‚¬ìš©ìì—ê²Œ ì§ì ‘ "ë‹¹ì‹ ì€ ì¸ì§€ ì˜¤ë¥˜ê°€ ìˆë„¤ìš”"ì²˜ëŸ¼ ë§í•˜ì§€ ì•Šì•„.)

[ëŒ€í™” ì›ì¹™]
- ê³µê°/ê²½ì²­/ë°˜ì˜/ì—´ë¦°ì§ˆë¬¸ ì¤‘ì‹¬. ì§§ê³  ë”°ëœ»í•˜ê²Œ(3~6ë¬¸ì¥).
- ê°•í•œ ë‹¨ì •/ì¶©ê³ /ì„¤êµ ê¸ˆì§€. "ë„ˆëŠ” ~êµ¬ë‚˜" ëŒ€ì‹  "~ë¼ê³  ëŠë¼ëŠ”êµ¬ë‚˜", "~ê·¸ë ‡ê²Œ ìƒê°í–ˆêµ¬ë‚˜"ë¼ê³  ë§í•´ì¤˜.
- â˜…[í•µì‹¬ ë¶„ì„ ì›ì¹™]â˜…: ê°ì •[C]ì— ê³µê°í•œ ë’¤, ê·¸ ê°ì •ì„ ìœ ë°œí•œ 'ì‚¬ê³ '[B]ë‚˜ 'ê³„ê¸°'[A]ë¥¼ ë¬»ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•´.
    - (C ê³µê°): "ì •ë§ ë¶ˆì•ˆí–ˆê² ë‹¤.", "ê·¸ëŸ° ë§ì„ ë“¤ìœ¼ë‹ˆ ê¸°ë¶„ì´ ë§ì´ ìƒí–ˆêµ¬ë‚˜."
    - (A ì§ˆë¬¸): "ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ ì¡°ê¸ˆ ë” ë§í•´ì¤„ ìˆ˜ ìˆì–´?", "ì£¼ë¡œ ì–´ë–¨ ë•Œ ê·¸ëŸ° ê¸°ë¶„ì´ ë“¤ì–´?"
    - (B ì§ˆë¬¸): "ê·¸ëŸ° ìƒí™©ì—ì„œ 'ì–´ë–¤ ìƒê°'ì´ ê°€ì¥ ë¨¼ì € ë“¤ì—ˆì–´?", "í˜¹ì‹œ 'ë‚˜ëŠ” ì™œ ì´ëŸ´ê¹Œ' ê°™ì€ ìì±…í•˜ëŠ” ìƒê°ì´ ë“¤ì—ˆì–´?", "ê·¸ ë§ì„ ë“¤ì—ˆì„ ë•Œ 'ë‚˜ë¥¼ ë¬´ì‹œí•˜ë‚˜?' í•˜ëŠ” ìƒê°ì´ ë“¤ì—ˆì–´?"

[ê¸ˆì§€/ì œí•œ]
- ì˜í•™ì /ì •ì‹ ê±´ê°• ì§„ë‹¨, ì¹˜ë£Œ/ì•½ë¬¼/ë²•ë¥  íŒë‹¨ ê¸ˆì§€.
- 'ì¸ì§€ ì˜¤ë¥˜', 'ìë™ì  ì‚¬ê³ ', 'ë¹„í•©ë¦¬ì  ì‹ ë…' ê°™ì€ ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©ìì—ê²Œ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆ.
- ì‚¬ìš©ìì˜ ìƒê°ì„ ì„£ë¶ˆë¦¬ 'í‹€ë ¸ë‹¤'ê³  êµì •í•˜ê±°ë‚˜ í›ˆê³„í•˜ì§€ ë§ˆ.

[ì•ˆì „]
- (ê¸°ì¡´ê³¼ ë™ì¼: ì/íƒ€í•´ ìœ„í—˜ ì‹œ 119, 1393 ì¦‰ì‹œ ì•ˆë‚´)
"""

# [ìˆ˜ì •ë¨] ì‚¬ìš©ìê°€ ì œê³µí•œ SAFETY_MSG ìœ ì§€
SAFETY_MSG = (
    "ì§€ê¸ˆ ë§ˆìŒì´ ë§ì´ í˜ë“¤ì–´ ë³´ì—¬.\n"
    "í˜¹ì‹œ ìŠ¤ìŠ¤ë¡œë¥¼ í•´ì¹  ìƒê°ì´ ë“¤ê±°ë‚˜ ì•ˆì „ì´ ìœ„í˜‘ë°›ëŠ”ë‹¤ë©´, ì§€ê¸ˆ ë°”ë¡œ 010-9201-7911 ë˜ëŠ” 010-5915-4693 ë˜ëŠ” 010-2629-2536 ë˜ëŠ” 1393(ìì‚´ì˜ˆë°© ìƒë‹´ì „í™”)ë¡œ ì—°ë½í•´ì¤˜.\n"
    "ë„ˆì˜ ì•ˆì „ì´ ê°€ì¥ ì¤‘ìš”í•´. ë‚´ê°€ ê³ì—ì„œ ë„ìš¸ê²Œ."
)

# â”€â”€ 1) ìœ„ê¸°(í¬ë¦¬ì‹œìŠ¤) ë£° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CRISIS_PATTERNS = [
    r"ìì‚´", r"ì£½ê³ \s*ì‹¶", r"ëë‚´ê³ \s*ì‹¶", r"ì‚´ê¸°\s*í˜ë“¤", r"í•´ì¹˜ê³ \s*ì‹¶",
    r"ìœ ì„œ", r"ì‚¬ëŠ”ê²Œ\s*ë¬´ì˜ë¯¸", r"ì—†ì–´ì¡Œìœ¼ë©´", r"ì†ëª©", r"ê·¹ë‹¨ì ì¸?\s*ìƒê°",
    r"ë›°ì–´ë‚´ë¦¬", r"ëª©ìˆ¨", r"ì‚¬ë¼ì§€ê³ \s*ì‹¶"
]
def is_crisis(text: str) -> bool:
    return any(re.search(p, text, re.IGNORECASE) for p in CRISIS_PATTERNS)

# â”€â”€ 2) LLM í˜¸ì¶œ(ë§¥ë½ + SDK í˜¸í™˜ + 429/503 ì¬ì‹œë„) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HISTORY_MAX_TURNS = 8
history: List[Dict[str, str]] = []

def make_contents(user_text: str) -> List[Dict[str, Any]]:
    msgs: List[Dict[str, Any]] = []
    # system_instruction ë¯¸ì§€ì› SDK ëŒ€ë¹„: ê·œì¹™ì„ ì²« user ë©”ì‹œì§€ë¡œ ì£¼ì…
    msgs.append({"role": "user", "parts": [{"text": f"[ì‹œìŠ¤í…œ ê·œì¹™]\n{SYSTEM}"}]})
    for m in history[-HISTORY_MAX_TURNS*2:]:
        msgs.append({
            "role": "user" if m["role"] == "user" else "model",
            "parts": [{"text": m["text"]}]
        })
    msgs.append({"role": "user", "parts": [{"text": user_text}]})
    return msgs

def _raw_generate(model: str, contents: list, temperature: float, max_output_tokens: int):
    # SDK ì‹ /êµ¬ë²„ì „ í˜¸í™˜: generation_config ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì œê±°
    try:
        return client.models.generate_content(
            model=model,
            contents=contents,
            generation_config={"temperature": temperature, "max_output_tokens": max_output_tokens},
        )
    except TypeError:
        return client.models.generate_content(model=model, contents=contents)

def safe_generate_content(model: str, contents: list, temperature: float = 0.7, max_output_tokens: int = 512):
    # 429/503 ëŒ€ë¹„ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„ + ì§€í„°)
    attempts = 5
    for i in range(attempts):
        try:
            return _raw_generate(model, contents, temperature, max_output_tokens)
        except (ServerError, ClientError) as e:
            msg = getattr(e, "message", str(e))
            transient = any(s in msg for s in [
                "UNAVAILABLE", "RESOURCE_EXHAUSTED", "overloaded", "quota", "temporarily"
            ])
            if i < attempts - 1 and transient:
                sleep = (0.6 * (2 ** i)) + random.uniform(0, 0.3)  # 0.6, 1.2, 2.4, ...
                print(f"âš ï¸ ì¬ì‹œë„ ì¤€ë¹„({i+1}/{attempts-1})â€¦ ì ì‹œ ëŒ€ê¸°: {sleep:.2f}s")
                time.sleep(sleep)
                continue
            raise

def generate_reply(user_text: str) -> str:
    try:
        resp = safe_generate_content(MODEL, make_contents(user_text), temperature=0.7, max_output_tokens=512)
        return (getattr(resp, "text", "") or "").strip()
    except ClientError as e:
        msg = getattr(e, "message", str(e))
        if "API key not valid" in msg or "API_KEY_INVALID" in msg:
            return "API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ì–´ìš”. .envì˜ GEMINI_API_KEYê°€ Google AI Studioì—ì„œ ë°œê¸‰ëœ í‚¤ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”."
        return f"ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {msg}"
    except ServerError as e:
        msg = getattr(e, "message", str(e))
        return f"ì„œë²„ê°€ í˜¼ì¡í•´ ì‘ë‹µì´ ì–´ë ¤ì›Œìš”(ì¼ì‹œ ì˜¤ë¥˜). ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ìƒì„¸: {msg}"
    except Exception as e:
        return f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}"

# â”€â”€ 3) ë©”ì¸ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_FILE = "chat_logs.jsonl"  # [ì¶”ê°€] ë¡œê·¸ íŒŒì¼ ì´ë¦„ ì§€ì •

def main():
    print("ğŸ‘¤ ì‚¬ìš©ìì—ê²Œ 'ì¢…ë£Œ' ì…ë ¥ ì‹œ ì¢…ë£Œë©ë‹ˆë‹¤.")
    while True:
        try:
            user = input("ğŸ‘¤ ì‚¬ìš©ì: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ¤– ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."); break

        if user.lower() in ["ì¢…ë£Œ", "quit", "exit"]:
            print("ğŸ¤– ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."); break
        if not user:
            continue

        reply = SAFETY_MSG if is_crisis(user) else generate_reply(user)
        print("ğŸ¤– ì±—ë´‡:", reply)

        history.append({"role": "user", "text": user})
        history.append({"role": "assistant", "text": reply})

        # [ì¶”ê°€ë¨] 2ë‹¨ê³„: ëŒ€í™” ë‚´ìš©ì„ JSONL íŒŒì¼ì— ì €ì¥
        try:
            log_entry = {
                "timestamp": datetime.now().isoformat(),  # í˜„ì¬ ì‹œê°„
                "user": user,
                "assistant": reply
            }
            # 'a' (append) ëª¨ë“œë¡œ ì—´ê³ , í•œê¸€(utf-8)ì´ ê¹¨ì§€ì§€ ì•Šê²Œ(ensure_ascii=False) ì €ì¥
            with open(LOG_FILE, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
        except Exception as e:
            print(f"âš ï¸ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()